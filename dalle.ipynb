{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "118UKH5bWCGa"
      },
      "source": [
        "Setup up the notebook.  The first two cells only needs to be run if you are using google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lok42MJuDrUq"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q dalle-mini==0.1.3\n",
        "!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp6aLgq77vxF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9d96OGv1wIj"
      },
      "source": [
        "Set up the dalle model.  You will need a weights and biases account to get an API key (don't worry, it's free to create an account)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4WRkQ_WDrUr"
      },
      "outputs": [],
      "source": [
        "# Model references\n",
        "\n",
        "# dalle-mega\n",
        "DALLE_MODEL = \"dalle-mini/dalle-mini/mega-1-fp16:latest\"  # can be wandb artifact or ðŸ¤— Hub or local folder or google bucket\n",
        "DALLE_COMMIT_ID = None\n",
        "\n",
        "# if the notebook crashes too often you can use dalle-mini instead by uncommenting below line\n",
        "# DALLE_MODEL = \"dalle-mini/dalle-mini/mini-1:v0\"\n",
        "\n",
        "# VQGAN model\n",
        "VQGAN_REPO = \"dalle-mini/vqgan_imagenet_f16_16384\"\n",
        "VQGAN_COMMIT_ID = \"e93a26e7707683d349bf5d5c41c5b0ef69b677a9\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv-aR3t4Oe5v"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# check how many devices are available\n",
        "jax.local_device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92zYmvsQ38vL"
      },
      "outputs": [],
      "source": [
        "# Load models & tokenizer\n",
        "from dalle_mini import DalleBart, DalleBartProcessor\n",
        "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
        "from transformers import CLIPProcessor, FlaxCLIPModel\n",
        "\n",
        "# Load dalle-mini\n",
        "model, params = DalleBart.from_pretrained(\n",
        "    DALLE_MODEL, revision=DALLE_COMMIT_ID, dtype=jnp.float16, _do_init=False\n",
        ")\n",
        "\n",
        "# Load VQGAN\n",
        "vqgan, vqgan_params = VQModel.from_pretrained(\n",
        "    VQGAN_REPO, revision=VQGAN_COMMIT_ID, _do_init=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxaapqL35Oid"
      },
      "source": [
        "Import everything we'll need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER6GcebE2OpO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "from flax.jax_utils import replicate\n",
        "from functools import partial\n",
        "from dalle_mini import DalleBartProcessor\n",
        "from flax.training.common_utils import shard_prng_key\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQcq-4Gq-rwT"
      },
      "outputs": [],
      "source": [
        "# Model parameters are replicated on each device for faster inference.\n",
        "params = replicate(params)\n",
        "vqgan_params = replicate(vqgan_params)\n",
        "\n",
        "# Model functions are compiled and parallelized to take advantage of multiple devices.\n",
        "# model inference\n",
        "@partial(jax.pmap, axis_name=\"batch\", static_broadcasted_argnums=(3, 4, 5, 6))\n",
        "def p_generate(\n",
        "    tokenized_prompt, key, params, top_k, top_p, temperature, condition_scale\n",
        "):\n",
        "    return model.generate(\n",
        "        **tokenized_prompt,\n",
        "        prng_key=key,\n",
        "        params=params,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        temperature=temperature,\n",
        "        condition_scale=condition_scale,\n",
        "    )\n",
        "\n",
        "\n",
        "# decode image\n",
        "@partial(jax.pmap, axis_name=\"batch\")\n",
        "def p_decode(indices, params):\n",
        "    return vqgan.decode_code(indices, params=params)\n",
        "\n",
        "# create a random key\n",
        "seed = random.randint(0, 2**32 - 1)\n",
        "key = jax.random.PRNGKey(seed)\n",
        "\n",
        "processor = DalleBartProcessor.from_pretrained(DALLE_MODEL, revision=DALLE_COMMIT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpXHx5aNVyvD"
      },
      "source": [
        "Load the prompts dataset.  There are 200 prompts which are all a variation on the following vague theme:\n",
        "\n",
        "> A  {gender}  with  an  object\n",
        "\n",
        "where {gender} is replaced either \"man\", \"woman\", \"boy\" or \"girl\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndql-LgIO6kx"
      },
      "outputs": [],
      "source": [
        "# Load the dataset of prompts\n",
        "prompts_db = []\n",
        "with open('/content/prompts.csv', newline='') as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
        "    i = 0\n",
        "    # Iterate over and print out all rows\n",
        "    for row in spamreader:\n",
        "      print(row)\n",
        "      # Skip the first row (i.e. the column headers)\n",
        "      if i > 0 and row:\n",
        "        prompts_db.append(row)\n",
        "      i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDjEx9JxR3v8"
      },
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = \"/content/drive/My Drive/dalle_results/\"\n",
        "try: \n",
        "    os.mkdir(output_dir) \n",
        "except OSError as error: \n",
        "    print(error)  \n",
        "\n",
        "# number of predictions per prompt\n",
        "n_predictions = 1\n",
        "\n",
        "# We can customize generation parameters (see https://huggingface.co/blog/how-to-generate)\n",
        "gen_top_k = None\n",
        "gen_top_p = None\n",
        "temperature = None\n",
        "cond_scale = 10.0\n",
        "\n",
        "# Iterate over every pair of prompts\n",
        "for i in range(3, int(len(prompts_db) / 4)):\n",
        "    idx = int(i * 4)\n",
        "    # Iterate over the man/woman/boy/girl variations\n",
        "    for j in range(4):\n",
        "        # Fix double spaces in prompts\n",
        "        prompt = prompts_db[idx+j][3][1:].replace('  ', ' ')\n",
        "        print(j, prompt)\n",
        "        prompts = [\n",
        "            \"sunset over a lake in the mountains\",\n",
        "        ]\n",
        "        # convert string to tokens\n",
        "        tokenized_prompt = processor([prompt,])\n",
        "\n",
        "        # replicate the prompts onto each device.\n",
        "        tokenized_prompt = replicate(tokenized_prompt)\n",
        "\n",
        "        # Generate 5 images for each prompt\n",
        "        repetitions = 5\n",
        "        for r in range(repetitions):\n",
        "            # Set seed for reproducability\n",
        "            key = jax.random.PRNGKey(int(prompts_db[idx+j][1]) + (r * 100))\n",
        "            # get a new key\n",
        "            key, subkey = jax.random.split(key)\n",
        "            # generate images\n",
        "            encoded_images = p_generate(\n",
        "                tokenized_prompt,\n",
        "                shard_prng_key(subkey),\n",
        "                params,\n",
        "                gen_top_k,\n",
        "                gen_top_p,\n",
        "                temperature,\n",
        "                cond_scale,\n",
        "            )\n",
        "            # remove BOS\n",
        "            encoded_images = encoded_images.sequences[..., 1:]\n",
        "            # decode images\n",
        "            decoded_images = p_decode(encoded_images, vqgan_params)\n",
        "            decoded_images = decoded_images.clip(0.0, 1.0).reshape((-1, 256, 256, 3))\n",
        "            for decoded_img in decoded_images:\n",
        "                img = Image.fromarray(np.asarray(decoded_img * 255, dtype=np.uint8))\n",
        "                display(img)\n",
        "                img.save(output_dir + prompts_db[idx+j][0] + '_' + str(r) + \".png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
